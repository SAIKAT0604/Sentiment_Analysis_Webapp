{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eneeyByENKZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "feac1160-387e-4f87-a2f0-6fddb81b2302"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 8000\n",
        "MAXLEN = 500\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n",
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 32)          256000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 264,353\n",
            "Trainable params: 264,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx-g-Yp5NS_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "ebbe60a2-19f5-4b9c-bd6e-c934e683036c"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 64s 102ms/step - loss: 0.4330 - acc: 0.8015 - val_loss: 0.2918 - val_acc: 0.8826\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 63s 100ms/step - loss: 0.2753 - acc: 0.8936 - val_loss: 0.3043 - val_acc: 0.8806\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 62s 100ms/step - loss: 0.2347 - acc: 0.9133 - val_loss: 0.2935 - val_acc: 0.8760\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 63s 100ms/step - loss: 0.2108 - acc: 0.9205 - val_loss: 0.2930 - val_acc: 0.8784\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 62s 100ms/step - loss: 0.1920 - acc: 0.9294 - val_loss: 0.5816 - val_acc: 0.8116\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 62s 99ms/step - loss: 0.1794 - acc: 0.9335 - val_loss: 0.2932 - val_acc: 0.8922\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 62s 100ms/step - loss: 0.1664 - acc: 0.9389 - val_loss: 0.2868 - val_acc: 0.8878\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 62s 100ms/step - loss: 0.1612 - acc: 0.9433 - val_loss: 0.2928 - val_acc: 0.8836\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 62s 100ms/step - loss: 0.1468 - acc: 0.9481 - val_loss: 0.3008 - val_acc: 0.8938\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 62s 99ms/step - loss: 0.1418 - acc: 0.9495 - val_loss: 0.3141 - val_acc: 0.8916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc7b4e76208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjjrq2-5Na0J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5d913390-995f-4443-d3ae-c17841d83cfd"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 23s 30ms/step - loss: 0.3533 - acc: 0.8758\n",
            "[0.3532625734806061, 0.875760018825531]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ODPfykhaC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f1287268-b24b-47a8-b0a7-0907cbf3b478"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRWGex7Hk6mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/sentiment_analysis_model_new.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLWW9eG2lI8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2= tf.keras.models.load_model('/content/drive/My Drive/sentiment_analysis_model_new.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwjhvY6flx60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0abfd6dc-0fcc-4b7b-f384-eba9a4a9afbc"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,MAXLEN))\n",
        "  pred[0] = encoded_text\n",
        "  result = model2.predict(pred)\n",
        "  if result[0]>0.5:\n",
        "    print(\"Positive Review\") \n",
        "  else:\n",
        "    print(\"Negative Review\") \n",
        "  #print(result[0])\n",
        "\n",
        "predict(\"That movie was great! really loved it and would watch it again because it was amazingly great\")\n",
        "predict(\"That movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Review\n",
            "Negative Review\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}